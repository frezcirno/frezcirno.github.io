<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin=""><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin=""><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222"><link rel="manifest" href="/images/site.webmanifest"><meta name="google-site-verification" content="_2IFmyB6MWp-By-cUpcYN7YPQVlR79Myfqb8mKJvGY8"><meta name="msvalidate.01" content="18B2BF72408DBD213F31F967D458F288"><style>:root{--body-bg-color:#eee;--content-bg-color:#fff;--card-bg-color:#f5f5f5;--text-color:#555;--selection-bg:#262a30;--selection-color:#eee;--blockquote-color:#666;--link-color:#555;--link-hover-color:#222;--brand-color:#fff;--brand-hover-color:#fff;--table-row-odd-bg-color:#f9f9f9;--table-row-hover-bg-color:#f5f5f5;--menu-item-bg-color:#f5f5f5;--theme-color:#222;--btn-default-bg:#fff;--btn-default-color:#555;--btn-default-border-color:#555;--btn-default-hover-bg:#222;--btn-default-hover-color:#fff;--btn-default-hover-border-color:#222;--highlight-background:#fff;--highlight-foreground:#24292e;--highlight-gutter-background:#fff;--highlight-gutter-foreground:#393e42;--lightningcss-light:initial;color-scheme:light}@media (prefers-color-scheme:dark){:root{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--selection-bg:#bbb;--selection-color:#333;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--theme-color:#222;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#0d1117;--highlight-foreground:#c9d1d9;--highlight-gutter-background:#1f242a;--highlight-gutter-foreground:#b6bdc5;--lightningcss-dark:initial;color-scheme:dark}img{opacity:.75}img:hover{opacity:.9}iframe{--lightningcss-light:initial;color-scheme:light}}html{-webkit-text-size-adjust:100%;line-height:1.15}body{margin:0}main{display:block}h1{margin:.67em 0;font-size:2em}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace;font-size:1em}a{background:0 0}abbr[title]{border-bottom:none;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace;font-size:1em}small{font-size:80%}sub,sup{vertical-align:baseline;font-size:75%;line-height:0;position:relative}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}button::-moz-focus-inner{border-style:none;padding:0}[type=button]::-moz-focus-inner{border-style:none;padding:0}[type=reset]::-moz-focus-inner{border-style:none;padding:0}[type=submit]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring{outline:1px dotted buttontext}[type=button]:-moz-focusring{outline:1px dotted buttontext}[type=reset]:-moz-focusring{outline:1px dotted buttontext}[type=submit]:-moz-focusring{outline:1px dotted buttontext}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;white-space:normal;max-width:100%;padding:0;display:table}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button{height:auto}[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}details{display:block}summary{display:list-item}[hidden],template{display:none}::selection{background:var(--selection-bg);color:var(--selection-color)}body,html{height:100%}body{background:var(--body-bg-color);box-sizing:border-box;color:var(--text-color);min-height:100%;font-family:PingFang SC,Sitka Text,Noto Sans SC,Microsoft YaHei,sans-serif;font-size:1em;line-height:2;transition:padding .2s ease-in-out;position:relative}h1,h2,h3,h4,h5,h6{margin:30px 0 15px;font-family:PingFang SC,Sitka Text,Noto Sans SC,Microsoft YaHei,sans-serif;font-weight:700;line-height:1.5}h1{font-size:1.5em}h2{font-size:1.375em}h3{font-size:1.25em}h4{font-size:1.125em}h5{font-size:1em}h6{font-size:.875em}a{color:var(--link-color);cursor:pointer;overflow-wrap:break-word;border-bottom:1px solid #999;outline:0;text-decoration:none}a:hover{border-bottom-color:var(--link-hover-color);color:var(--link-hover-color)}embed,iframe,img,video{max-width:100%;margin-left:auto;margin-right:auto;display:block}hr{background-image:repeating-linear-gradient(-45deg,#ddd,#ddd 4px,#0000 4px 8px);border:0;height:3px;margin:40px 0}blockquote{color:var(--blockquote-color);border-left:4px solid #ddd;margin:0;padding:0 15px}blockquote cite:before{content:"-";padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}.table-container{overflow:auto}table{border-collapse:collapse;border-spacing:0;width:100%;margin:0 0 20px;font-size:.875em}tbody tr:nth-of-type(odd){background:var(--table-row-odd-bg-color)}tbody tr:hover{background:var(--table-row-hover-bg-color)}caption,td,th{padding:8px}td,th{border:1px solid #ddd;border-bottom-width:3px}th{padding-bottom:10px;font-weight:700}td{border-bottom-width:1px}.btn{background:var(--btn-default-bg);border:2px solid var(--btn-default-border-color);color:var(--btn-default-color);border-radius:2px;padding:0 20px;font-size:.875em;line-height:2;transition:background-color .2s ease-in-out;display:inline-block}.btn:hover{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{text-align:left;width:1.28571em}.toggle{line-height:0}.toggle .toggle-line{background:#fff;width:100%;height:2px;transition:left .4s,opacity .4s,top .4s,transform .4s,width .4s;display:block;position:relative;top:0;left:0}.toggle .toggle-line:first-child{margin-top:1px}.toggle .toggle-line:not(:first-child){margin-top:4px}.toggle.toggle-arrow :first-child{width:50%;top:2px;left:50%;transform:rotate(45deg)}.toggle.toggle-arrow :last-child{width:50%;top:-2px;left:50%;transform:rotate(-45deg)}.toggle.toggle-close :nth-child(2){opacity:0}.toggle.toggle-close :first-child{top:6px;transform:rotate(45deg)}.toggle.toggle-close :last-child{top:-6px;transform:rotate(-45deg)}pre code.hljs{padding:1em;display:block;overflow-x:auto}code.hljs{padding:3px 5px}.hljs{color:#24292e;background:#fff}.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#d73a49}.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#6f42c1}.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#005cc5}.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#032f62}.hljs-built_in,.hljs-symbol{color:#e36209}.hljs-code,.hljs-comment,.hljs-formula{color:#6a737d}.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#22863a}.hljs-subst{color:#24292e}.hljs-section{color:#005cc5;font-weight:700}.hljs-bullet{color:#735c0f}.hljs-emphasis{color:#24292e;font-style:italic}.hljs-strong{color:#24292e;font-weight:700}.hljs-addition{color:#22863a;background-color:#f0fff4}.hljs-deletion{color:#b31d28;background-color:#ffeef0}@media (prefers-color-scheme:dark){pre code.hljs{padding:1em;display:block;overflow-x:auto}code.hljs{padding:3px 5px}.hljs{color:#c9d1d9;background:#0d1117}.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-template-tag,.hljs-template-variable,.hljs-type,.hljs-variable.language_{color:#ff7b72}.hljs-title,.hljs-title.class_,.hljs-title.class_.inherited__,.hljs-title.function_{color:#d2a8ff}.hljs-attr,.hljs-attribute,.hljs-literal,.hljs-meta,.hljs-number,.hljs-operator,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-variable{color:#79c0ff}.hljs-meta .hljs-string,.hljs-regexp,.hljs-string{color:#a5d6ff}.hljs-built_in,.hljs-symbol{color:#ffa657}.hljs-code,.hljs-comment,.hljs-formula{color:#8b949e}.hljs-name,.hljs-quote,.hljs-selector-pseudo,.hljs-selector-tag{color:#7ee787}.hljs-subst{color:#c9d1d9}.hljs-section{color:#1f6feb;font-weight:700}.hljs-bullet{color:#f2cc60}.hljs-emphasis{color:#c9d1d9;font-style:italic}.hljs-strong{color:#c9d1d9;font-weight:700}.hljs-addition{color:#aff5b4;background-color:#033a16}.hljs-deletion{color:#ffdcd7;background-color:#67060c}}.code-container:hover .copy-btn,.highlight:hover .copy-btn{opacity:1}.code-container{position:relative}.copy-btn{color:#333;cursor:pointer;opacity:0;background:#fff;border:0;padding:2px 6px;font-size:.8125em;line-height:1.6;transition:opacity .2s ease-in-out;position:absolute;top:0;right:0}code,figure.highlight,kbd,pre{background:var(--highlight-background);color:var(--highlight-foreground)}figure.highlight,pre{margin:0 auto 20px;line-height:1.6}figure.highlight figcaption,pre .caption{background:var(--highlight-gutter-background);color:var(--highlight-foreground);padding:.5em;font-size:.875em;line-height:1.2;display:flow-root}figure.highlight figcaption a,pre .caption a{color:var(--highlight-foreground);float:right}figure.highlight figcaption a:hover,pre .caption a:hover{border-bottom-color:var(--highlight-foreground)}code,pre{font-family:Roboto Mono,consolas,Menlo,monospace,PingFang SC,Microsoft YaHei}code{overflow-wrap:break-word;border-radius:3px;padding:2px 4px;font-size:.875em}kbd{white-space:nowrap;border:2px solid #ccc;border-radius:.2em;padding:.1em .3em;font-family:inherit;box-shadow:.1em .1em .2em #0000001a}figure.highlight{position:relative;overflow:auto}figure.highlight pre{border:0;margin:0;padding:10px 0}figure.highlight table{border:0;width:auto;margin:0}figure.highlight td{border:0;padding:0}figure.highlight .gutter{-webkit-user-select:none;user-select:none}figure.highlight .gutter pre{background:var(--highlight-gutter-background);color:var(--highlight-gutter-foreground);text-align:right;padding-left:10px;padding-right:10px}figure.highlight .code pre{width:100%;padding-left:10px}figure.highlight .marked{background:#0000004d}pre .caption{margin-bottom:10px}.gist table{width:auto}.gist table td{border:0}pre{padding:10px;overflow:auto}pre code{text-shadow:none;background:0 0;padding:0}.blockquote-center{text-align:center;border-left:0;margin:40px 0;padding:0;position:relative}.blockquote-center:after,.blockquote-center:before{opacity:.6;width:100%;line-height:1;position:absolute;left:0}.blockquote-center:before{text-align:left;content:"";border-top:1px solid #ccc;font-family:"Font Awesome 6 Free";font-weight:900;top:-20px}.blockquote-center:after{text-align:right;content:"";border-bottom:1px solid #ccc;font-family:"Font Awesome 6 Free";font-weight:900;bottom:-20px}.blockquote-center div,.blockquote-center p{text-align:center}.group-picture{margin-bottom:20px}.group-picture .group-picture-row{gap:3px;margin-bottom:3px;display:flex}.group-picture .group-picture-column{flex:1}.group-picture .group-picture-column img{object-fit:cover;width:100%;height:100%;margin:0}.post-body .label{color:#555;padding:0 2px}.post-body .label.default{background:#f0f0f0}.post-body .label.primary{background:#efe6f7}.post-body .label.info{background:#e5f2f8}.post-body .label.success{background:#e7f4e9}.post-body .label.warning{background:#fcf6e1}.post-body .label.danger{background:#fae8eb}.post-body .link-grid{grid-gap:1.5rem;grid-template-columns:repeat(auto-fill,minmax(300px,1fr));gap:1.5rem;margin-bottom:20px;padding:1rem;display:grid}.post-body .link-grid .link-grid-container{border:solid #ddd;min-width:0;min-height:5rem;padding:.5rem;transition:background .3s;position:relative;box-shadow:1rem 1rem .5rem #00000080}.post-body .link-grid .link-grid-container:hover{background:var(--card-bg-color);animation:.5s next-shake}.post-body .link-grid .link-grid-container:active{transform:translate(.2rem,.2rem);box-shadow:.5rem .5rem .25rem #00000080}.post-body .link-grid .link-grid-container .link-grid-image{box-sizing:border-box;border:1px solid #ddd;border-radius:50%;width:5rem;height:5rem;padding:3px;position:absolute}.post-body .link-grid .link-grid-container p{margin:0 1rem 0 6rem}.post-body .link-grid .link-grid-container p:first-of-type{font-size:1.2em}.post-body .link-grid .link-grid-container p:last-of-type{opacity:.7;font-size:.8em;line-height:1.3rem}.post-body .link-grid .link-grid-container a{border:0;width:100%;height:100%;position:absolute;top:0;left:0}@keyframes next-shake{0%{transform:translate(1pt,1pt) rotate(0)}10%{transform:translate(-1pt,-2pt) rotate(-1deg)}20%{transform:translate(-3pt) rotate(1deg)}30%{transform:translate(3pt,2pt) rotate(0)}40%{transform:translate(1pt,-1pt) rotate(1deg)}50%{transform:translate(-1pt,2pt) rotate(-1deg)}60%{transform:translate(-3pt,1pt) rotate(0)}70%{transform:translate(3pt,1pt) rotate(-1deg)}80%{transform:translate(-1pt,-1pt) rotate(1deg)}90%{transform:translate(1pt,2pt) rotate(0)}to{transform:translate(1pt,-2pt) rotate(-1deg)}}.post-body .note{border:1px solid #eee;border-left-width:5px;border-radius:3px;margin-bottom:20px;padding:1em;position:relative}.post-body .note summary{cursor:pointer;outline:0}.post-body .note summary p{display:inline}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{border-bottom:initial;margin:0;padding-top:0}.post-body .note :first-child{margin-top:0}.post-body .note :last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .tabs{margin-bottom:20px}.post-body .tabs,.tabs-comment{padding-top:10px}.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{background:var(--content-bg-color);z-index:5;flex-wrap:wrap;justify-content:center;margin:0;padding:0;display:flex;position:sticky;top:0}@media (max-width:413px){.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{margin-bottom:5px;display:block}}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border:1px solid #0000;border-top-width:3px;border-bottom-color:#ddd;border-radius:0;flex-grow:1;list-style-type:none}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border:1px solid #0000;border-left-width:3px;border-radius:0}}.post-body .tabs ul.nav-tabs li.tab a,.tabs-comment ul.nav-tabs li.tab a{border-bottom:initial;text-align:center;padding:.25em .75em;line-height:1.8;transition:all .2s ease-out;display:block}.post-body .tabs ul.nav-tabs li.tab a i[class^=fa],.tabs-comment ul.nav-tabs li.tab a i[class^=fa]{width:1.28571em}.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#fc6423 #ddd #0000}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#ddd #ddd #ddd #fc6423}}.post-body .tabs ul.nav-tabs li.tab.active a,.tabs-comment ul.nav-tabs li.tab.active a{cursor:default}.post-body .tabs .tab-content,.tabs-comment .tab-content{border:1px solid #ddd;border-top-color:#0000;border-radius:0}@media (max-width:413px){.post-body .tabs .tab-content,.tabs-comment .tab-content{border-top-color:#ddd;border-radius:0}}.post-body .tabs .tab-content .tab-pane,.tabs-comment .tab-content .tab-pane{padding:20px 20px 0}.post-body .tabs .tab-content .tab-pane:not(.active),.tabs-comment .tab-content .tab-pane:not(.active){display:none}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:-1px 10px 0;padding:0 10px;display:inline-block}@media (max-width:767px){.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}}.pagination .page-number.current{color:var(--content-bg-color);background:#ccc;border-color:#ccc}.pagination{text-align:center;border-top:1px solid #eee;margin:120px 0 0}.pagination .next,.pagination .page-number,.pagination .prev{border-top:1px solid #eee;border-bottom:0;transition:border-color .2s ease-in-out}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:var(--link-hover-color)}@media (max-width:767px){.pagination{border-top:0}.pagination .next,.pagination .page-number,.pagination .prev{border-top:0;border-bottom:1px solid #eee}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:var(--link-hover-color)}}.pagination .space{margin:0;padding:0}.comments{margin-top:60px;overflow:hidden}.comment-button-group{flex-wrap:wrap;justify-content:center;margin:1em 0;display:flex}.comment-button-group .comment-button{margin:.1em .2em}.comment-button-group .comment-button.active{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.comment-position{display:none}.comment-position.active{display:block}.tabs-comment{margin-top:4em;padding-top:0}.tabs-comment .comments{margin-top:0;padding-top:0}.headband{background:var(--theme-color);height:0}@media (max-width:991px){.headband{display:none}}.site-brand-container{flex-shrink:0;padding:0 10px;display:flex}.use-motion .column,.use-motion .site-brand-container .toggle{opacity:0}.site-meta{text-align:center;flex-grow:1}@media (max-width:767px){.site-meta{text-align:center}}.custom-logo-image{margin-top:20px}@media (max-width:991px){.custom-logo-image{display:none}}.brand{color:var(--brand-color);border-bottom:0;padding:0;display:inline-block}.brand:hover{color:var(--brand-hover-color)}.site-title{margin:0;font-family:PingFang SC,Sitka Text,Noto Sans SC,Microsoft YaHei,sans-serif;font-size:1.5em;font-weight:400;line-height:1.5}.site-subtitle{color:#ddd;margin:10px 10px 0;font-size:.8125em}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-right,.site-nav-toggle{display:none}@media (max-width:767px){.site-nav-right,.site-nav-toggle{flex-direction:column;justify-content:center;display:flex}}.site-nav-right .toggle,.site-nav-toggle .toggle{color:var(--text-color);width:22px;padding:10px}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:var(--text-color);border-radius:1px}@media (max-width:767px){.site-nav{--scroll-height:0;visibility:hidden;height:0;transition:height .2s ease-in-out,visibility .2s ease-in-out;overflow:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu{text-align:center;margin:0;padding:1em 0}.menu-item{margin:0 10px;list-style:none;display:inline-block}@media (max-width:767px){.menu-item{margin-top:10px;display:block}.menu-item.menu-item-search{display:none}}.menu-item a{border-bottom:0;font-size:.8125em;transition:border-color .2s ease-in-out;display:block}.menu-item a.menu-item-active,.menu-item a:hover{background:var(--menu-item-bg-color)}.menu-item i[class^=fa]{margin-right:8px}.menu-item .badge{color:var(--content-bg-color);text-shadow:1px 1px #0000001a;background:#ccc;border-radius:10px;margin-left:.35em;padding:2px 5px;font-weight:700;line-height:1}.use-motion .menu-item{visibility:hidden}@media (max-width:991px){.sidebar{left:-320px}.sidebar-active .sidebar{left:0}.sidebar{z-index:20;background:#222;width:320px;max-height:100vh;transition:left .2s ease-out,right .2s ease-out;position:fixed;top:0;bottom:0;overflow-y:auto;box-shadow:inset 0 2px 6px #000}.sidebar a{color:#999;border-bottom-color:#555}.sidebar a:hover{color:#eee;border-bottom-color:#eee}.links-of-author:not(:first-child){margin-top:15px}.links-of-author a{vertical-align:middle;border-bottom-color:#555;margin-bottom:10px;margin-right:10px;transition:all .2s ease-in-out;display:inline-block}.links-of-author a:before{content:" ";background:#c286ff;border-radius:50%;width:4px;height:4px;margin-right:3px;display:inline-block;transform:translateY(-2px)}.links-of-blogroll-item{padding:0 5px}.popular-posts .popular-posts-item .popular-posts-link:hover{background:0 0}.sidebar-dimmer{opacity:0;visibility:hidden;z-index:10;background:#000;width:100%;height:100%;transition:visibility .4s,opacity .4s;position:fixed;top:0;left:0}.sidebar-active .sidebar-dimmer{opacity:.7;visibility:visible}}.sidebar-inner{color:#999;text-align:center;flex-direction:column;justify-content:center;padding:18px 10px;display:flex}.sidebar-toggle{cursor:pointer;opacity:.6;z-index:30;background:#222;width:16px;height:16px;padding:5px;position:fixed;bottom:61px;left:30px}@media (max-width:991px){.sidebar-toggle{left:20px}}.sidebar-toggle:hover{opacity:.8}@media (max-width:991px){.sidebar-toggle{opacity:.8}}.sidebar-toggle:hover .toggle-line{background:#fc6423}@media (any-hover:hover){body:not(.sidebar-active) .sidebar-toggle:hover :first-child{width:50%;top:2px;left:50%;transform:rotate(45deg)}body:not(.sidebar-active) .sidebar-toggle:hover :last-child{width:50%;top:-2px;left:50%;transform:rotate(-45deg)}}.sidebar-active .sidebar-toggle :nth-child(2){opacity:0}.sidebar-active .sidebar-toggle :first-child{top:6px;transform:rotate(45deg)}.sidebar-active .sidebar-toggle :last-child{top:-6px;transform:rotate(-45deg)}.sidebar-nav{pointer-events:none;visibility:hidden;height:0;margin:0;padding-left:0;font-size:.875em;transition:height .2s ease-in-out,visibility .2s ease-in-out;overflow:hidden}.sidebar-nav-active .sidebar-nav{pointer-events:unset;height:calc(2em + 1px);visibility:unset}.sidebar-nav li{color:var(--text-color);cursor:pointer;border-bottom:1px solid #0000;transition:border-bottom-color .2s ease-in-out,color .2s ease-in-out;display:inline-block}.sidebar-nav li.sidebar-nav-overview{margin-left:10px}.sidebar-nav li:hover{color:#fc6423}.sidebar-overview-active .sidebar-nav-overview,.sidebar-toc-active .sidebar-nav-toc{color:#fc6423;border-bottom-color:#fc6423;transition-delay:.2s}.sidebar-overview-active .sidebar-nav-overview:hover,.sidebar-toc-active .sidebar-nav-toc:hover{color:#fc6423}.sidebar-panel-container{flex:1;align-items:start;padding-top:0;transition:padding-top .2s ease-in-out;display:grid;overflow:hidden auto}.sidebar-nav-active .sidebar-panel-container{padding-top:20px}.sidebar-panel{opacity:0;pointer-events:none;visibility:hidden;grid-area:1/1;height:0;transition:opacity .2s ease-in-out,transform .2s ease-in-out,visibility .2s ease-in-out;animation:.2s ease-in-out deactivate-sidebar-panel;overflow:hidden;transform:translateY(0)}.sidebar-nav-active .sidebar-panel,.sidebar-overview-active .sidebar-panel.post-toc-wrap{transform:translateY(-20px)}.sidebar-overview-active:not(.sidebar-nav-active) .sidebar-panel.post-toc-wrap{transition-delay:0s,.2s,0s}.sidebar-overview-active .sidebar-panel.site-overview-wrap,.sidebar-toc-active .sidebar-panel.post-toc-wrap{opacity:1;pointer-events:unset;height:auto;visibility:unset;transition-delay:.2s,.2s,0s;animation-name:activate-sidebar-panel;transform:translateY(0)}.sidebar-panel.site-overview-wrap{flex-direction:column;justify-content:flex-start;gap:10px;display:flex}@keyframes deactivate-sidebar-panel{0%{height:var(--inactive-panel-height,0)}to{height:var(--active-panel-height,0)}}@keyframes activate-sidebar-panel{0%{height:var(--inactive-panel-height,auto)}to{height:var(--active-panel-height,auto)}}.post-toc{font-size:.875em}.post-toc ol{text-align:left;margin:0;padding:0 2px 0 10px;list-style:none}.post-toc ol>:last-child{margin-bottom:5px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition:all .2s ease-in-out}.post-toc .nav-item{text-overflow:ellipsis;white-space:nowrap;line-height:1.8;overflow:hidden}.post-toc .nav .active>a{color:#fc6423;border-bottom-color:#fc6423}.post-toc .nav .active-current>a,.post-toc .nav .active-current>a:hover{color:#fc6423}.site-author-image{border:1px solid #eee;border-radius:50%;max-width:120px;padding:2px;transition:transform 1s ease-out}.site-author-image:hover{transform:rotate(360deg)}.site-author-name{color:var(--text-color);margin:0;font-weight:600}.site-description{color:#999;margin-top:0;font-size:.8125em}.site-state{flex-wrap:wrap;justify-content:center;line-height:1.4;display:flex}.site-state-item{padding:0 15px}.site-state-item a{border-bottom:0;display:block}.site-state-item-count{font-size:1em;font-weight:600;display:block}.site-state-item-name{color:#999;font-size:.8125em}.sidebar .sidebar-button:not(:first-child){margin-top:15px}.sidebar .sidebar-button button{color:#fc6423;cursor:pointer;background:0 0;border:1px solid #fc6423;border-radius:4px;padding:0 15px;line-height:2}.sidebar .sidebar-button button:hover{color:#fff;background:#fc6423}.sidebar .sidebar-button button i[class^=fa]{margin-right:5px}.links-of-author a{font-size:.8125em}.links-of-author i[class^=fa]{margin-right:2px}.cc-license .cc-opacity{opacity:.7;border-bottom:0}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}.links-of-blogroll{font-size:.8125em}.links-of-blogroll-title{font-size:.875em;font-weight:600}.links-of-blogroll-list{flex-flow:column wrap;justify-content:center;gap:5px;margin:5px 0 0;padding:0;list-style:none;display:flex}.links-of-blogroll-item{max-width:100%}.links-of-blogroll-item a{box-sizing:border-box;text-overflow:ellipsis;white-space:nowrap;max-width:100%;display:inline-block;overflow:hidden}.sidebar-post-related{padding:18px 0 0;font-size:.8125em}.popular-posts{text-align:left;margin:0;padding:1em 0}.popular-posts .popular-posts-item{display:block}.popular-posts .popular-posts-item .popular-posts-link{border-bottom:0;padding:5px 20px;transition:background .2s ease-in-out;display:block}.popular-posts .popular-posts-item .popular-posts-link:hover{background:var(--menu-item-bg-color)}.popular-posts .popular-posts-item .popular-posts-time{color:#999}.footer{color:#999;padding:20px 0;font-size:.875em;transition:left .2s ease-in-out,right .2s ease-in-out}.footer.footer-fixed{position:absolute;bottom:0;left:0;right:0}.footer-inner{box-sizing:border-box;text-align:center;flex-direction:column;justify-content:center;width:calc(100% - 20px);margin:0 auto;display:flex}@media (max-width:767px){.footer-inner{width:auto}}@media (min-width:1200px){.footer-inner{width:1160px}}@media (min-width:1600px){.footer-inner{width:73%}}.use-motion .footer{opacity:0}.languages{font-size:1.125em;display:inline-block;position:relative}.languages .lang-select-label span{margin:0 .5em}.languages .lang-select{opacity:0;width:100%;height:100%;position:absolute;top:0;left:0}.with-love{color:gray;margin:0 5px;display:inline-block}.busuanzi-count #busuanzi_container_site_pv,.busuanzi-count #busuanzi_container_site_uv{display:none}@keyframes icon-animate{0%,to{transform:scale(1)}10%,30%{transform:scale(.9)}20%,40%,60%,80%{transform:scale(1.1)}50%,70%{transform:scale(1.1)}}.back-to-top{color:#fff;cursor:pointer;opacity:.6;z-index:30;background:#222;align-items:center;height:26px;font-size:12px;transition:bottom .2s ease-in-out;display:flex;position:fixed;bottom:-100px;left:30px}.back-to-top span{margin-right:8px;display:none}.back-to-top .fa{text-align:center;width:26px}@media (max-width:991px){.back-to-top{left:20px}}.back-to-top:hover{opacity:.8}@media (max-width:991px){.back-to-top{opacity:.8}}.back-to-top:hover{color:#fc6423}.back-to-top.back-to-top-on{bottom:30px}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.post-button{text-align:center;margin-top:40px}.use-motion .collection-header,.use-motion .comments,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{visibility:hidden}.posts-collapse .post-content{margin-bottom:35px;margin-left:35px;position:relative}@media (max-width:767px){.posts-collapse .post-content{margin-left:0;margin-right:0}}.posts-collapse .post-content .collection-title{font-size:1.125em;position:relative}.posts-collapse .post-content .collection-title:before{content:" ";background:#999;border:1px solid #fff;border-radius:50%;width:10px;height:10px;margin-top:-4px;margin-left:-6px;position:absolute;top:50%}.posts-collapse .post-content .collection-year{margin:60px 0;font-size:1.4em;font-weight:700;position:relative}.posts-collapse .post-content .collection-year .collection-year-count{color:var(--content-bg-color);text-shadow:1px 1px #0000001a;background:#ccc;border-radius:10px;margin-left:.35em;padding:2px 5px;font-size:.75em;font-weight:700;line-height:1}.posts-collapse .post-content .collection-year:before{content:" ";background:#bbb;border-radius:50%;width:8px;height:8px;margin-top:-4px;margin-left:-4px;position:absolute;top:50%}.posts-collapse .post-content .collection-header{margin-left:20px;display:block}.posts-collapse .post-content .collection-header small{color:#bbb;margin-left:5px}.posts-collapse .post-content .post-header{border-bottom:1px dashed #ccc;margin:30px 2px 0;padding-left:15px;transition:border .2s ease-in-out;position:relative}.posts-collapse .post-content .post-header:before{content:" ";background:#bbb;border:1px solid #fff;border-radius:50%;width:6px;height:6px;transition:background .2s ease-in-out;position:absolute;top:.75em;left:-6px}.posts-collapse .post-content .post-header:hover{border-bottom-color:#666}.posts-collapse .post-content .post-header:hover:before{background:#222}.posts-collapse .post-content .post-meta-container{margin-right:10px;font-size:.75em;display:inline}.posts-collapse .post-content .post-title{display:inline}.posts-collapse .post-content .post-title a{color:var(--link-color);border-bottom:0}.posts-collapse .post-content .post-title .fa{margin-left:5px;font-size:.875em}.posts-collapse .post-content:before{content:" ";background:#f5f5f5;width:4px;height:100%;margin-left:-2px;position:absolute;top:1.25em}.post-body{overflow-wrap:break-word;font-family:PingFang SC,Sitka Text,Noto Sans SC,Microsoft YaHei,sans-serif}@media (min-width:1200px){.post-body{font-size:1.125em}}@media (min-width:992px){.post-body{text-align:justify}}@media (max-width:991px){.post-body{text-align:justify}}.post-body h1 .header-anchor,.post-body h1 .headerlink,.post-body h2 .header-anchor,.post-body h2 .headerlink,.post-body h3 .header-anchor,.post-body h3 .headerlink,.post-body h4 .header-anchor,.post-body h4 .headerlink,.post-body h5 .header-anchor,.post-body h5 .headerlink,.post-body h6 .header-anchor,.post-body h6 .headerlink{color:inherit;float:right;opacity:0;border-bottom-style:none;margin-left:10px;font-size:.875em}.post-body h1 .header-anchor:before,.post-body h1 .headerlink:before,.post-body h2 .header-anchor:before,.post-body h2 .headerlink:before,.post-body h3 .header-anchor:before,.post-body h3 .headerlink:before,.post-body h4 .header-anchor:before,.post-body h4 .headerlink:before,.post-body h5 .header-anchor:before,.post-body h5 .headerlink:before,.post-body h6 .header-anchor:before,.post-body h6 .headerlink:before{content:"";font-family:"Font Awesome 6 Free";font-weight:900}.post-body h1:hover .header-anchor,.post-body h1:hover .headerlink,.post-body h2:hover .header-anchor,.post-body h2:hover .headerlink,.post-body h3:hover .header-anchor,.post-body h3:hover .headerlink,.post-body h4:hover .header-anchor,.post-body h4:hover .headerlink,.post-body h5:hover .header-anchor,.post-body h5:hover .headerlink,.post-body h6:hover .header-anchor,.post-body h6:hover .headerlink{opacity:.5}.post-body h1:hover .header-anchor:hover,.post-body h1:hover .headerlink:hover,.post-body h2:hover .header-anchor:hover,.post-body h2:hover .headerlink:hover,.post-body h3:hover .header-anchor:hover,.post-body h3:hover .headerlink:hover,.post-body h4:hover .header-anchor:hover,.post-body h4:hover .headerlink:hover,.post-body h5:hover .header-anchor:hover,.post-body h5:hover .headerlink:hover,.post-body h6:hover .header-anchor:hover,.post-body h6:hover .headerlink:hover{opacity:1}.post-body .exturl .fa{margin-left:4px;font-size:.875em}.post-body figure:not(.highlight) figcaption{color:#999;text-align:center;margin:-15px auto 15px;font-size:.875em;font-weight:700;line-height:1}.post-body embed,.post-body iframe,.post-body img,.post-body video{margin-bottom:20px}.post-body .video-container{width:100%;height:0;margin-bottom:20px;padding-top:75%;position:relative;overflow:hidden}.post-body .video-container embed,.post-body .video-container iframe,.post-body .video-container object{width:100%;height:100%;margin:0;position:absolute;top:0;left:0}.post-gallery{min-height:200px;display:flex}.post-gallery .post-gallery-image{flex:1}.post-gallery .post-gallery-image:not(:first-child){clip-path:polygon(40px 0,100% 0,100% 100%,0 100%);margin-left:-20px}.post-gallery .post-gallery-image:not(:last-child){margin-right:-20px}.post-gallery .post-gallery-image img{object-fit:cover;opacity:1;width:100%;height:100%}.posts-expand .post-gallery{margin-bottom:60px}.posts-collapse .post-gallery{margin:15px 0}.posts-expand .post-header{text-align:center;margin-bottom:60px;font-size:1.125em}.posts-expand .post-title{margin:initial;overflow-wrap:break-word;font-size:1.4em;font-weight:400}.posts-expand .post-title-link{color:var(--link-color);border-bottom:0;display:inline-block;position:relative}.posts-expand .post-title-link:before{background:var(--link-color);content:"";width:100%;height:2px;transition:transform .2s ease-in-out;position:absolute;bottom:0;left:0;transform:scaleX(0)}.posts-expand .post-title-link:hover:before{transform:scaleX(1)}.posts-expand .post-title-link .fa{margin-left:5px;font-size:.875em}.post-sticky-flag{margin-right:8px;display:inline-block;transform:rotate(30deg)}.posts-expand .post-meta-container{color:#999;margin-top:3px;font-family:PingFang SC,Sitka Text,Noto Sans SC,Microsoft YaHei,sans-serif;font-size:.75em}.posts-expand .post-meta-container .post-description{margin-top:2px;font-size:.875em}.posts-expand .post-meta-container time{border-bottom:1px dashed #999}.post-meta{flex-wrap:wrap;justify-content:center;display:flex}:not(.post-meta-break)+.post-meta-item:before{content:"|";margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (max-width:991px){.post-meta-item-text{display:none}}.post-meta-break{flex-basis:100%;height:0}#busuanzi_container_page_pv{display:none}.post-nav{border-top:1px solid #eee;justify-content:space-between;gap:30px;margin-top:1em;padding:10px 5px 0;display:flex}.post-nav-item{flex:1}.post-nav-item a{border-bottom:0;font-size:.875em;line-height:1.6;display:block}.post-nav-item a:active{top:2px}.post-nav-item .fa{font-size:.75em}.post-nav-item:first-child .fa{margin-right:5px}.post-nav-item:last-child{text-align:right}.post-nav-item:last-child .fa{margin-left:5px}.post-footer{flex-direction:column;justify-content:center;display:flex}.post-eof{background:#ccc;width:8%;height:1px;margin:80px auto 60px}.post-block:last-of-type .post-eof{display:none}.post-copyright ul{background:var(--card-bg-color);border-left:3px solid #ff2a2a;margin:1em 0 0;padding:.5em 1em;list-style:none;position:relative;overflow:hidden}.post-copyright ul:after{content:"";opacity:.1;font-family:"Font Awesome 6 Brands";font-size:200px;position:absolute;top:-150px;right:-50px}.post-tags{text-align:center;margin-top:40px}.post-tags a{font-size:.8125em;display:inline-block}.post-tags a:not(:last-child){margin-right:10px}.social-like{border-top:1px solid #eee;flex-wrap:wrap;justify-content:center;margin-top:1em;padding-top:1em;font-size:.875em;display:flex}.social-like a{border-bottom:none}.reward-container{text-align:center;margin:1em 0 0;padding:1em 0}.reward-container button{color:#fc6423;cursor:pointer;vertical-align:text-top;background:0 0;border:2px solid #fc6423;border-radius:2px;outline:0;padding:0 15px;line-height:2}.reward-container button:hover{color:#fff;background:#fc6423}.post-reward{padding-top:20px;display:none}.post-reward.active{display:block}.post-reward div{display:inline-block}.post-reward div span{display:block}.post-reward img{width:180px;max-width:100%;margin:.8em 2em 0;display:inline-block}@keyframes next-roll{0%{transform:rotate(30deg)}to{transform:rotate(-30deg)}}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{margin:0;padding:0;list-style:none}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{color:var(--content-bg-color);text-shadow:1px 1px #0000001a;background:#ccc;border-radius:10px;margin-left:.35em;padding:2px 5px;font-size:.75em;font-weight:700;line-height:1}.category-all-page .category-list-child{padding-left:10px}.event-list hr{background:#222;margin:20px 0 45px}.event-list hr:after{color:#fff;content:"NOW";background:#222;padding:0 5px;font-weight:700;display:inline-block}.event-list .event{--event-background:#222;--event-foreground:#bbb;--event-title:#fff;background:var(--event-background);padding:15px}.event-list .event .event-summary{color:var(--event-title);border-bottom:0;margin:0;padding:0 0 0 35px;position:relative}.event-list .event .event-summary:before{background:var(--event-title);content:" ";border-radius:50%;width:12px;height:12px;margin-top:-6px;animation:1s ease-in-out infinite alternate dot-flash;position:absolute;top:50%;left:0}.event-list .event:nth-of-type(odd) .event-summary:before{animation-delay:.5s}.event-list .event:not(:last-child){margin-bottom:20px}.event-list .event .event-relative-time{color:var(--event-foreground);padding-left:12px;font-size:12px;font-weight:400;display:inline-block}.event-list .event .event-details{color:var(--event-foreground);padding:6px 0 6px 35px;line-height:18px;display:block}.event-list .event .event-details:before{color:var(--event-foreground);width:14px;margin-right:9px;font-family:"Font Awesome 6 Free";font-weight:900;display:inline-block}.event-list .event .event-details.event-location:before{content:""}.event-list .event .event-details.event-duration:before{content:""}.event-list .event .event-details.event-description:before{content:""}.event-list .event-past{--event-background:#f5f5f5;--event-foreground:#999;--event-title:#222}@keyframes dot-flash{0%{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}ul.breadcrumb{text-align:center;margin:1em 0;padding:0 2em;font-size:.75em;list-style:none}ul.breadcrumb li{display:inline}ul.breadcrumb li:not(:first-child):before{content:"/ ";padding:.5em;font-weight:400}ul.breadcrumb li:last-child{font-weight:700}.tag-cloud{text-align:center}.tag-cloud a{margin:10px;display:inline-block}.tag-cloud-0{color:#aaa;border-bottom-color:#aaa}.tag-cloud-1{color:#9a9a9a;border-bottom-color:#9a9a9a}.tag-cloud-2{color:#8b8b8b;border-bottom-color:#8b8b8b}.tag-cloud-3{color:#7c7c7c;border-bottom-color:#7c7c7c}.tag-cloud-4{color:#6c6c6c;border-bottom-color:#6c6c6c}.tag-cloud-5{color:#5d5d5d;border-bottom-color:#5d5d5d}.tag-cloud-6{color:#4e4e4e;border-bottom-color:#4e4e4e}.tag-cloud-7{color:#3e3e3e;border-bottom-color:#3e3e3e}.tag-cloud-8{color:#2f2f2f;border-bottom-color:#2f2f2f}.tag-cloud-9{color:#202020;border-bottom-color:#202020}.tag-cloud-10{color:#111;border-bottom-color:#111}@media (prefers-color-scheme:dark){.tag-cloud-0{color:#555;border-bottom-color:#555}.tag-cloud-1{color:#646464;border-bottom-color:#646464}.tag-cloud-2{color:#737373;border-bottom-color:#737373}.tag-cloud-3{color:#828282;border-bottom-color:#828282}.tag-cloud-4{color:#929292;border-bottom-color:#929292}.tag-cloud-5{color:#a1a1a1;border-bottom-color:#a1a1a1}.tag-cloud-6{color:#b0b0b0;border-bottom-color:#b0b0b0}.tag-cloud-7{color:silver;border-bottom-color:silver}.tag-cloud-8{color:#cfcfcf;border-bottom-color:#cfcfcf}.tag-cloud-9{color:#dedede;border-bottom-color:#dedede}.tag-cloud-10{color:#eee;border-bottom-color:#eee}}.utterances{max-width:unset}.search-active{overflow:hidden}.search-pop-overlay{visibility:hidden;z-index:40;background:0 0;width:100%;height:100%;transition:visibility .4s,background .4s;display:flex;position:fixed;top:0;left:0}.search-active .search-pop-overlay{visibility:visible;background:#0000004d}.search-popup{background:var(--card-bg-color);border-radius:5px;width:700px;height:80%;margin:auto;transition:transform .4s;transform:scale(0)}.search-active .search-popup{transform:scale(1)}@media (max-width:767px){.search-popup{border-radius:0;width:100%;height:100%}}.search-popup .popup-btn-close,.search-popup .search-icon{color:#999;padding:0 10px;font-size:18px}.search-popup .popup-btn-close{cursor:pointer}.search-popup .popup-btn-close:hover .fa{color:#222}.search-popup .search-header{background:#eee;border-top-left-radius:5px;border-top-right-radius:5px;padding:5px;display:flex}@media (prefers-color-scheme:dark){.search-popup .search-header{background:#666}}.search-popup input.search-input{background:0 0;border:0;outline:0;width:100%}.search-popup input.search-input::-webkit-search-cancel-button{display:none}.search-popup .search-result-container{flex-direction:column;height:calc(100% - 55px);padding:5px 25px;display:flex;overflow:auto}.search-popup .search-result-container hr{flex-shrink:0;margin:5px 0 10px}.search-popup .search-result-container hr:first-child{display:none}.search-popup .search-result-list{margin:0 5px;padding:0}.search-popup a.search-result-title{font-weight:700}.search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.search-popup .search-input-container{flex-grow:1;padding:2px}.search-popup .search-result-icon{color:#ccc;margin:auto}mark.search-keyword{color:#ff2a2a;background:0 0;border-bottom:1px dashed #ff2a2a;font-weight:700}.search-stats{justify-content:space-between;align-items:center;display:flex}.search-stats img{height:1em;margin:0}.pagination.algolia-pagination{visibility:visible;margin-top:auto;padding:40px 0}.use-motion .animated{visibility:inherit;animation-fill-mode:none}.use-motion .sidebar .animated{animation-fill-mode:both}header.header{background:var(--content-bg-color);border-radius:10px;box-shadow:0 2px 4px #0000000d}@media (max-width:991px){header.header{border-radius:initial}}.main{justify-content:space-between;align-items:stretch;width:calc(100% - 20px);margin:0 auto;display:flex}@media (max-width:767px){.main{width:auto}}@media (min-width:1200px){.main{width:1160px}}@media (min-width:1600px){.main{width:73%}}@media (max-width:991px){.main{width:auto;display:block}}.main-inner{box-sizing:border-box;border-radius:10px;width:calc(100% - 260px)}@media (max-width:991px){.main-inner{border-radius:initial;width:100%}}.footer-inner{padding-left:260px}@media (max-width:991px){.footer-inner{width:auto;padding-left:0;padding-right:0}}.column{width:240px}@media (max-width:991px){.column{width:auto}}.site-brand-container{background:var(--theme-color)}@media (max-width:991px){.site-nav-on .site-brand-container{box-shadow:0 0 16px #00000080}}.site-meta{padding:20px 0}@media (min-width:768px) and (max-width:991px){.site-nav-right,.site-nav-toggle{flex-direction:column;justify-content:center;display:flex}}.site-nav-right .toggle,.site-nav-toggle .toggle{color:#fff}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:#fff}@media (min-width:768px) and (max-width:991px){.site-nav{--scroll-height:0;visibility:hidden;height:0;transition:height .2s ease-in-out,visibility .2s ease-in-out;overflow:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu .menu-item{margin:0;display:block}.menu .menu-item a{align-items:center;padding:5px 20px;transition-property:background-color;display:flex;position:relative}.menu .menu-item a .badge{margin-left:auto}@media (max-width:991px){.menu .menu-item.menu-item-search{display:none}}.sub-menu{margin:0;padding:6px 0}.sub-menu .menu-item{display:inline-block}.sub-menu .menu-item a{padding:initial;background:0 0;margin:5px 10px}.sub-menu .menu-item a:hover{color:#fc6423;background:0 0}.sub-menu .menu-item-active{color:#fc6423;border-bottom-color:#fc6423}.sub-menu .menu-item-active:hover{border-bottom-color:#fc6423}@media (min-width:992px){.sidebar{position:sticky;top:20px}.sidebar-toggle{display:none}.sidebar-inner{background:var(--content-bg-color);box-sizing:border-box;color:var(--text-color);border-radius:10px;max-height:calc(100vh - 40px);margin-top:20px;box-shadow:0 2px 4px #0000000d}.site-state-item{padding:0 10px}.sidebar .sidebar-button{border-top:1px dotted #ccc;border-bottom:1px dotted #ccc}.sidebar .sidebar-button button{color:#fc6423;border:0;width:100%;display:block}.sidebar .sidebar-button button:hover{color:#e34603;background:0 0;border:0}.links-of-author{flex-wrap:wrap;justify-content:center;display:flex}.links-of-author-item{width:50%;margin:5px 0 0}.links-of-author-item a{box-sizing:border-box;text-overflow:ellipsis;white-space:nowrap;border-bottom:0;border-radius:4px;max-width:100%;padding:0 5px;display:inline-block;overflow:hidden}.links-of-author-item a:hover{background:var(--body-bg-color)}.links-of-blogroll-item a{padding:0 5px}}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .post-block,.main-inner .sub-menu,.main-inner .tabs-comment,.main-inner>.comments{background:var(--content-bg-color);border-radius:10px;box-shadow:0 2px 4px #0000000d}.main-inner .post-block:not(:first-child):not(:first-child){border-radius:10px;margin-top:20px;box-shadow:0 2px 4px #0000000d}@media (min-width:768px) and (max-width:991px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:10px}}@media (max-width:767px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:8px}}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{border-radius:10px;margin-top:20px;box-shadow:0 2px 4px #0000000d}@media (min-width:768px) and (max-width:991px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:10px}}@media (max-width:767px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:8px}}.comments,.post-block{padding:40px}.post-eof{display:none}.pagination{border-top:initial;padding:10px 0}.post-body h1,.post-body h2{border-bottom:1px solid #eee}.post-body h3{border-bottom:1px dotted #eee}@media (min-width:768px) and (max-width:991px){.main-inner{padding:10px}.posts-expand .post-button{margin-top:20px}.post-block{padding:20px}.comments{padding:10px 20px}}@media (max-width:767px){.main-inner{padding:8px}.posts-expand .post-button{margin:20px 0}.post-block{padding:20px}.comments{padding:10px 20px}}.posts-expand{opacity:.95}.sidebar{opacity:.9}.header-inner{background:#ffffffe6}.popup{opacity:.9}.header-inner{overflow:hidden}@media (min-width:991px){.main{margin-top:40px}}.main-inner .post-block:not(:first-child):not(:first-child),.sidebar-inner{margin-top:20px}figure.highlight{border-radius:4px;overflow:hidden}figure.highlight .gutter pre{border-right:1px solid #c5c5c5}.site-brand-container{border-radius:10px 10px 3px 3px}.posts-expand .post-title{font-weight:700}.site-subtitle{font-size:.7em;font-style:italic}.site-author-name{font-variation-settings:"opsz" 24.6303,"wght" 700;font-family:Sitka Text,Noto Sans SC,PingFang SC,Microsoft YaHei,sans-serif;font-weight:700}.post-body h1 .header-anchor-1,.post-body h2 .header-anchor-1,.post-body h3 .header-anchor-1,.post-body h4 .header-anchor-1,.post-body h5 .header-anchor-1,.post-body h6 .header-anchor-1{color:inherit;float:left;-webkit-margin-start:calc(-.875em + .15em);opacity:0;border-bottom-style:none;margin-inline-start:-.725em;font-size:.875em;transition:opacity .2s}.post-body h1:hover .header-anchor-1,.post-body h2:hover .header-anchor-1,.post-body h3:hover .header-anchor-1,.post-body h4:hover .header-anchor-1,.post-body h5:hover .header-anchor-1,.post-body h6:hover .header-anchor-1{opacity:.5}.post-body h1:hover .header-anchor-1:hover,.post-body h2:hover .header-anchor-1:hover,.post-body h3:hover .header-anchor-1:hover,.post-body h4:hover .header-anchor-1:hover,.post-body h5:hover .header-anchor-1:hover,.post-body h6:hover .header-anchor-1:hover{opacity:1}.info,.tip{color:#185d8a;background-color:#bae2fc;border-left:4px solid #3498db;padding-left:10px}.success{color:#286f4f;background-color:#caffe7;border-left:4px solid #42b983;padding-left:10px}.warning{color:#8b7300;background-color:#fff7d0;border-left:4px solid #e7c000;padding-left:10px}.danger{color:#7a0000;background-color:#ffe6e6;border-left:4px solid #c00;padding-left:10px}.posts-expand .post-header{margin-bottom:30px}</style><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/orange/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script><script class="next-config" data-name="main" type="application/json">{"hostname":"frezcirno.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"algolia":{"appID":"2FQMQ0WT67","apiKey":"756d1525441f92ed29f8f7f9be42f683","indexName":"blog","hits":{"per_page":10}}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/config.min.js" defer></script><meta name="description" content="Megatron-LM是一种用于训练数十亿参数语言模型的新方法，该技术由NVIDIA推出，依托于模型并行技术，有效突破现代处理器的内存限制。自2019年发表以来，该论文已被引用超过2000次，展现了深度学习和自然语言处理领域的重大进展。本文详细探讨了Transformer架构的优化，实现了高效的模型训练策略，为研究人员提供了有价值的工具和理论支持，推动了NLP技术的发展。"><meta property="og:type" content="blog"><meta property="og:title" content="Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读"><meta property="og:url" content="https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/index.html"><meta property="og:site_name" content="tantan的博客"><meta property="og:description" content="Megatron-LM是一种用于训练数十亿参数语言模型的新方法，该技术由NVIDIA推出，依托于模型并行技术，有效突破现代处理器的内存限制。自2019年发表以来，该论文已被引用超过2000次，展现了深度学习和自然语言处理领域的重大进展。本文详细探讨了Transformer架构的优化，实现了高效的模型训练策略，为研究人员提供了有价值的工具和理论支持，推动了NLP技术的发展。"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2025-04-05T02:47:38.000Z"><meta property="article:modified_time" content="2025-08-17T07:24:53.758Z"><meta property="article:author" content="frezcirno"><meta property="article:tag" content="MLSys"><meta property="article:tag" content="Megatron-LM"><meta property="article:tag" content="Model Parallelism"><meta property="article:tag" content="Distributed Training"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/","path":"2025/04/05/megatron-lm-training-multi-billion-parameter/","title":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读 | tantan的博客</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y9HV7FT1HW"></script><script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-Y9HV7FT1HW","only_pageview":false,"measure_protocol_api_secret":null}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/analytics/google-analytics.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/utils.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/sidebar.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/next-boot.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/4.24.0/algoliasearch-lite.umd.js" integrity="sha256-b2n6oSgG4C1stMT/yc/ChGszs9EY/Mhs6oltEjQbFCQ=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/search/algolia-search.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/pace.min.js" defer></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin="anonymous"><script class="next-config" data-name="katex" type="application/json">{"copy_tex_js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/math/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous" defer></script><script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/"}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/quicklink.min.js" defer></script><script defer src="/assets/drawFlower.js"></script><style>@font-face{font-family:'Libertinus Serif';font-style:normal;font-weight:400;src:local('Libertinus Serif'),local('Libertinus-Serif'),url(https://frezcirno.github.io/static/Libertinus-7.040/static/WOFF2/LibertinusSerif-Regular.woff2) format('woff2');font-display:swap}@font-face{font-family:'Libertinus Sans';font-style:normal;font-weight:400;src:local('Libertinus Sans'),local('Libertinus-Sans'),url(https://frezcirno.github.io/static/Libertinus-7.040/static/WOFF2/LibertinusSans-Regular.woff2) format('woff2');font-display:swap}@font-face{font-family:'Libertinus Math';font-style:normal;font-weight:400;src:local('Libertinus Math'),local('Libertinus-Math'),url(https://frezcirno.github.io/static/Libertinus-7.040/static/WOFF2/LibertinusMath-Regular.woff2) format('woff2');font-display:swap}@font-face{font-family:'Roboto Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/robotomono/v23/L0xuDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vq_ROW4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Sitka Text';font-style:normal;font-display:swap;src:local('Sitka Text'),local('Sitka-Text'),url(https://frezcirno.github.io/static/Sitka/SitkaVF.woff) format('woff'),url(https://frezcirno.github.io/static/Sitka/SitkaVF.woff2) format('woff2')}@font-face{font-family:'Sitka Text';font-style:italic;font-display:swap;src:local('Sitka Text'),local('Sitka-Text'),url(https://frezcirno.github.io/static/Sitka/SitkaVF-Italic.woff) format('woff'),url(https://frezcirno.github.io/static/Sitka/SitkaVF-Italic.woff2) format('woff2')}</style><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">tantan的博客</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">Notes, ideas, and observations</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">30</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">167</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fab fa-algolia fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%BC%95%E8%A8%80"><span class="nav-text">1. 引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E8%83%8C%E6%99%AF%E4%B8%8E%E6%8C%91%E6%88%98"><span class="nav-text">2. 背景与挑战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E7%A5%9E%E7%BB%8F%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="nav-text">2.1. 神经语言模型预训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-transformer-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-text">2.2 Transformer 语言模型和多头注意力机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C"><span class="nav-text">2.3 深度学习中的数据并行和模型并行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C-transformer"><span class="nav-text">3. 模型并行 Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E8%AE%BE%E5%AE%9A"><span class="nav-text">4. 设定</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">4.1 训练数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%EF%BC%8C%E8%B6%85%E5%8F%82%E6%95%B0"><span class="nav-text">4.2 训练优化，超参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E5%AE%9E%E9%AA%8C"><span class="nav-text">5. 实验</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" width="120" height="120" itemprop="image" alt="frezcirno" src="https://frezcirno.github.io/static/avatar.webp"><p class="site-author-name" itemprop="name">frezcirno</p><div class="site-description" itemprop="description">编程爱好者</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">167</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">30</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">105</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZyZXpjaXJubw==" title="GitHub → https://github.com/frezcirno"><i class="fab fa-github fa-fw"></i> GitHub</span></span><span class="links-of-author-item"><span class="exturl" data-url="bWFpbHRvOnRhbnppeHVhbi5tZUBnbWFpbC5jb20=" title="E-Mail → mailto:tanzixuan.me@gmail.com"><i class="fa fa-envelope fa-fw"></i> E-Mail</span></span></div><div class="cc-license animated" itemprop="license"><span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span></div></div></div></div><div class="sidebar-inner sidebar-post-related"><div class="animated"><div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i> 相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><a class="popular-posts-link" href="/2021/01/10/modulo-arithmetic/" rel="bookmark"><time class="popular-posts-time">2021-01-10</time><br>模运算的性质(程序设计版)</a></li><li class="popular-posts-item"><a class="popular-posts-link" href="/2025/04/06/a-unified-architecture-for-accelerating/" rel="bookmark"><time class="popular-posts-time">2025-04-06</time><br>A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters 论文阅读</a></li><li class="popular-posts-item"><a class="popular-posts-link" href="/2025/04/04/a-generic-communication-scheduler/" rel="bookmark"><time class="popular-posts-time">2025-04-04</time><br>A Generic Communication Scheduler for Distributed DNN Training Acceleration 论文阅读</a></li><li class="popular-posts-item"><a class="popular-posts-link" href="/2025/04/04/horovod-fast-and-easy-distributed/" rel="bookmark"><time class="popular-posts-time">2025-04-04</time><br>Horovod: fast and easy distributed deep learning in TensorFlow 论文阅读</a></li></ul></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://frezcirno.github.io/static/avatar.webp"><meta itemprop="name" content="frezcirno"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="tantan的博客"><meta itemprop="description" content="编程爱好者"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读 | tantan的博客"><meta itemprop="description" content="Megatron-LM是一种用于训练数十亿参数语言模型的新方法，该技术由NVIDIA推出，依托于模型并行技术，有效突破现代处理器的内存限制。自2019年发表以来，该论文已被引用超过2000次，展现了深度学习和自然语言处理领域的重大进展。本文详细探讨了Transformer架构的优化，实现了高效的模型训练策略，为研究人员提供了有价值的工具和理论支持，推动了NLP技术的发展。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2025-04-05 10:47:38" itemprop="dateCreated datePublished" datetime="2025-04-05T10:47:38+08:00">2025-04-05</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/mlsys/" itemprop="url" rel="index"><span itemprop="name">mlsys</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-break"></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>2.7k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 ≈</span> <span>10 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>NVIDIA 出品的大模型训练方法，2019 年挂在 ArXiV 上，到现在(2025 年)有 2k+ 论文引用。</p><h2 id="1-引言"><a class="header-anchor-1" href="#1-引言">#</a>1. 引言</h2><p>得益于计算能力和数据集大小的增长，NLP 领域取得了飞速的进展。</p><p>随着这些模型变得越来越大，它们超出了现代处理器的内存限制，需要额外的内存管理技术，例如 Activation Checkpointing。广泛使用的优化算法，如 Adam，需要每个参数存储额外的信息例如动量和其他优化器状态，这降低了可以训练的模型的大小。几种模型并行方法通过按比例划分模型参数来解决这个问题，使得权重和优化器状态不需要同时存在于处理器上。例如，GPipe 和 Mesh TensorFlow 提供了各种模型并行化框架。然而，这些方法需要重写模型，并且依赖于自定义的编译器和框架。</p><p>在这项工作中，作者实现了一个简单而有效的模型并行方法，使用层内模型并行。作者利用了 Transformer 架构的内存结构来实现简单的模型并行实现，可以高效地在 PyTorch 中进行训练，无需自定义 C++代码或者编译器。这种方法于 GPipe 等方法所倡导的基于管道的模型并行方法正交。</p><h2 id="2-背景与挑战"><a class="header-anchor-1" href="#2-背景与挑战">#</a>2. 背景与挑战</h2><h3 id="2-1-神经语言模型预训练"><a class="header-anchor-1" href="#2-1-神经语言模型预训练">#</a>2.1. 神经语言模型预训练</h3><p>预训练语言模型已经是 NLP 中不可或缺的组成部分。这些方法的进步需要高效的硬件、系统技术和框架。本文的工作旨在提供必要的工具，以便在这个趋势中迈出一步。</p><h3 id="2-2-transformer-语言模型和多头注意力机制"><a class="header-anchor-1" href="#2-2-transformer-语言模型和多头注意力机制">#</a>2.2 Transformer 语言模型和多头注意力机制</h3><p>由于其优越的准确性和计算效率，当前的 NLP 趋势是使用 Transformer 模型。原始的 Transformer 模型是一种机器翻译架构，分为编码器和解码器两个部分。然而，最近（2019 年）的工作，如 BERT 和 GPT-2 只使用了 Transformer 的编码器或解码器部分。</p><h3 id="2-3-深度学习中的数据并行和模型并行"><a class="header-anchor-1" href="#2-3-深度学习中的数据并行和模型并行">#</a>2.3 深度学习中的数据并行和模型并行</h3><p>有两种主要的方法来利用大量硬件加速器以扩展深度学习模型：<em>数据并行</em>（1990）和<em>模型并行</em>。数据并行方法中，每个 minibatch 被划分到多个 Worker 上。模型并行方法中，模型的内存使用和计算分布在多个 Worker 上。通过成比例增加 minibatch 大小和 Worker 数量的比例，可以观测到接近线性增长的训练数据吞吐量。然而，大的训练 batch 会引入优化过程的复杂性，可能导致准确性降低、或者收敛速度变慢，从而抵消了吞吐量增加的好处。 Parallel work 结合了数据并行和激活检查点方法来减少内存的需求。</p><p>然而，这些技术有一个共同的缺点：模型必须能完全放入 Worker 的内存中。随着语言模型越来越大和复杂，神经网络已经接近这个限制。解决这个问题的一个方法是使用参数共享(2019)来减少模型的内存占用，但是会限制模型的整体容量。本文的方法是使用模型并行来将模型分布在多个 GPU 上，这不仅缓解了内存压力，还增加了与 minibatch 大小无关的并行性。</p><p>在模型并行中，还有两个其他的范式：<em>层间流水线并行</em>，和更通用的<em>分布式张量计算</em>。在流水线模型并行中，在一个设备上先执行一组操作，然后输出会被传递到流水线上的下一个设备，在上面进行另一组操作。一些方法使用参数服务器和流水线并行相结合。然而会遇到不一致的问题，这种方法需要额外的处理逻辑，以及对优化器本身进行修改，而这些修改会降低效率或者影响准确性。</p><p>分布式张量计算是一种正交而且更加通用的方法，它将一个张量操作分布在多个设备上，以加速计算或者增加模型大小。 FlexFlow(Jia et al., 2018)提出了一种选择最优并行化策略的方法。最近，Mesh-TensorFlow(Shazeer et al., 2018)引入了一种语言来指定 TensorFlow 中的一般类分布张量计算。该语言由用户定义维度，使用适当的聚合原语编译生成的图。我们与 Mesh-TensorFlow 有类似的见解，但是我们没有实现新的框架和编译器，而是对现有的 PyTorch Transformer 实现进行了少量针对性的修改。我们的方法简单易懂，不需要任何新的编译器或者代码重写，通过插入一些简单的原语就可以完全实现，如下一节所述。</p><h2 id="3-模型并行-transformer"><a class="header-anchor-1" href="#3-模型并行-transformer">#</a>3. 模型并行 Transformer</h2><p>本文利用了 Transformer 的网络结构，通过添加几个同步原语来实现一个简单的模型并行。 Transformer 层由一个 Self Attention 后跟一个 MLP 组成，我们在两个块中分别引入了模型并行性。</p><p>首先介绍 MLP 块。MLP 块的第一部分是 GEMM，然后是 GeLU。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>X</mi><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y=GeLU(XA)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:.10903em">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span></span></p><p>并行化 GEMM 的一种方法是按行拆分权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">A</span></span></span></span>，按列拆分输入矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span></span></span></span>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mspace linebreak="newline"></mspace><mi>A</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>A</mi><mn>2</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mspace linebreak="newline"></mspace><mi>Y</mi><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><msub><mi>A</mi><mn>1</mn></msub><mo>+</mo><msub><mi>X</mi><mn>2</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X=[X_1, X_2] \\ A=\begin{bmatrix} A_1 \\ A_2 \end{bmatrix} \\ Y=GeLU(X_1 A_1 + X_2 A_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-.95em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.95em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">]</span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:.10903em">LU</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>因为 GeLU 是一个非线性函数，不能继续拆分成两个 GeLU 的和，这种方法需要在 GeLU 函数之前就插入同步点。</p><p>另一种选择是按列拆分<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">A = [A_1, A_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>。这种分区允许我们对每个分区的 GEMM 结果独立应用 GeLU 非线性：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>u</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[Y_1, Y_2]=[GeLU(X A_1), GeLu(X A_2)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:.10903em">LU</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal">Lu</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)]</span></span></span></span></span></p><p>这种划分有利于消除同步点。因此，我们采用了这种方法。在分块进行第二次 GEMM 之后，进行 Reduce，然后进行 Dropout 层。这种方法将 MLP 块中的两个 GEMM 都分布在 GPU 上，并且只需要 Forward 和 Backward 各一次 All-Reduce。这两个操作彼此共轭，而且可以在 PyTorch 中使用几行代码实现。例如下面的代码实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">f</span>(torch.autograd.Function):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, gradient</span>):</span><br><span class="line">        all_reduce(gradient)</span><br><span class="line">        <span class="keyword">return</span> gradient</span><br></pre></td></tr></tbody></table></figure><p>对于 Self Attention，我们利用了 Multihead Attention 操作中的固有并行性，按照 K, Q 和 V 划分 GEMM 操作，这样每个 Attention 头对应的矩阵乘法都在一个 GPU 上本地执行。这使得我们能够将每个 Attention 头的参数和工作负载分布在多个 GPU 上，并且不需要任何即时通信就可以完成 Self Attention 的计算。输出 linear 层之后的 GEMM 按照行并行化，并直接采用并行注意力层的输出，无需 GPU 之间的通信。这种方法融合了两组 GEMM，去掉了中间一个同步点，并带来了更好的拓展性。这使得我们能够只使用 Forward/Backward 各两次 All-Reduce 的情况下，实现简单 Transformer 层中所有的 GEMM 计算。</p><p>Transformer 语言模型有一个 Hidden-size(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span>) x Vocabulary-size(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span></span></span></span>) 大小的输入 Embedding 层。由于现代语言模型的词表通常在万级别（例如，GPT-2 是 50,257 个），因此对输出 Embedding 层进行并行化是有好处的。然而，在 Transformer 语言模型中，输入和输出 Embedding 层共享权重，需要进行修改。我们按照单词维度并行化输入 Embedding 权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>H</mi><mo>×</mo><mi>v</mi></mrow></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi>E</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>E</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_{H\times v} = [E_1, E_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8917em;vertical-align:-.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:-.0576em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0576em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0576em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>。现在因为每个分片只包含 Embedding 表个一部分，在输入 Embedding 之后需要一次 All-Reduce。</p><p>对于输出 Embedding，一种办法是进行并行<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>E</mi><mi>M</mi><mi>M</mi><mo stretchy="false">[</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>X</mi><msub><mi>E</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>X</mi><msub><mi>E</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">GEMM[Y_1, Y_2] = [X E_1, X E_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">GEMM</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0576em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0576em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> 获取 logits，加上一次 All-gather 操作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>a</mi><mi>l</mi><mi>l</mi><mo>−</mo><mi>g</mi><mi>a</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y=all-gather([Y_1, Y_2])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.7778em;vertical-align:-.0833em"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:.01968em">ll</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:.02778em">er</span><span class="mopen">([</span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">])</span></span></span></span>，然后把结果发给 Cross-Entropy 损失函数。然而，All-gather 操作需要通信 <span class="katex-error" title="ParseError: KaTeX parse error: Expected 'EOF', got '_' at position 12: \text{batch_̲size} \times \t…" style="color:#999">\text{batch_size} \times \text{seq_len} \times v</span> 个元素，由于词表大小<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span></span></span></span>很大，总体通信也很大。为了减少通信大小，作者将并行<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>E</mi><mi>M</mi><mi>M</mi><mo stretchy="false">[</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">GEMM[Y_1, Y_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">GEMM</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>的输出与 Cross-Entropy 聚合在一起，将维度降低至<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>×</mo><mi>s</mi></mrow><annotation encoding="application/x-tex">b \times s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7778em;vertical-align:-.0833em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">s</span></span></span></span>。只通信标量的损失而不是 logits，极大地减少了通信量，提高了模型并行方法的效率。</p><p>我们的模型并发方法的主要特点是减少通信并保持 GPU 计算量。我们选择在多个 GPU 之间复制计算，而不是让一个 GPU 进行一部分计算然后广播结果。具体来说，我们在每个 GPU 上维护 LayerNorm 的参数，并在把参数输出到下一部分之前，在这些 Tensor 上进行 Dropout 和残差连接。为了优化模型，我们允许每个 Worker 优化自己的参数集合。由于所有的参数要么是 GPU 局部的，要么被拷贝过，因此不需要额外的通信去更新参数值。</p><p>简而言之，我们的方法实现简单，只需要在 Forward 和 Backward 的过程中增加一些额外的 All-Reduce 操作。不需要编辑器，而且与流水线模型并行方案正交。</p><h2 id="4-设定"><a class="header-anchor-1" href="#4-设定">#</a>4. 设定</h2><p>预训练语言理解模型是 NLP 和语言理解的核心任务。语言模型有几种方法。在本文中，我们关注 GPT-2，一种基于 Transformer 的自左向右的生成式语言模型，以及 BERT，一种基于语言模型掩码的双向 Transformer 模型。我们在下一部分解释这些模型的配置。</p><h3 id="4-1-训练数据集"><a class="header-anchor-1" href="#4-1-训练数据集">#</a>4.1 训练数据集</h3><p>包含 Wikipedia + CC-Stories + RealNews + OpenWebtext - WikiText103。 BERT 数据集额外包括 BookCorpus。过滤掉长度小于 128 个 token 的文档，使用 LSH 消除相似度大于 0.7 的重复内容。最终得到 174GB 的去重文本。</p><h3 id="4-2-训练优化，超参数"><a class="header-anchor-1" href="#4-2-训练优化，超参数">#</a>4.2 训练优化，超参数</h3><p>采用了带 Dynamic Loss Scaling 的 Mixed Precision 训练，以更好地利用 V100 的张量核心。权重初始化<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mtext>&nbsp;</mtext><mi>N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>0.02</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W~N(0, 0.02)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace nobreak">&nbsp;</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">0.02</span><span class="mclose">)</span></span></span></span>。在残差连接之前将权重乘以<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><msqrt><mrow><mn>2</mn><mi>N</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">1/\sqrt{2N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1767em;vertical-align:-.25em"></span><span class="mord">1/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9267em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord">2</span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span><span style="top:-2.8867em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95 702c-2.7 0-7.17-2.7-13.5-8-5.8-5.3-9.5-10-9.5-14 0-2 .3-3.3 1-4 1.3-2.7 23.83-20.7 67.5-54 44.2-33.3 65.8-50.3 66.5-51 1.3-1.3 3-2 5-2 4.7 0 8.7 3.3 12 10s173 378 173 378c.7 0 35.3-71 104-213 68.7-142 137.5-285 206.5-429 69-144 104.5-217.7 106.5-221l0 0c5.3-9.3 12-14 20-14H400000v40H845.2724s-225.272 467-225.272 467-235 486-235 486c-2.7 4.7-9 7-19 7-6 0-10-1-12-3s-194-422-194-422-65 47-65 47zM834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1133em"><span></span></span></span></span></span></span></span></span>，其中 N 是 Transformer 层的数量。对于优化器，使用带 Weight Decay（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">\lambda=0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">0.01</span></span></span></span>） 的 Adam 优化器。使用了 1.0 的全局 Gradient Norm Clipping 来提升训练稳定性。 Dropout 使用 0.1。在每个 Transformer 之后使用 Activation Checkpointing。</p><p>对于 GPT-2 模型，Batch size 设定为 512，输入序列长度是 1024 个 subword，迭代 300k 次。学习率在前 3k 次迭代是 1.5e-4，后续采用单周期余弦衰减，在达到 1e-5 之后停止衰减。</p><p>对于 BERT 模型，使用了大小为 30522 的原始词典。使用 Sentence Order Prediction 替换了 Next Sentence Prediction 任务。使用 整词 n-gram 掩码。 Batch size 设定为 1024，学习率为 1.0e-4，Warmup 10k 次，然后在剩下来的 2m 次迭代中线性衰减。</p><h2 id="5-实验"><a class="header-anchor-1" href="#5-实验">#</a>5. 实验</h2><p>TODO</p></div><footer class="post-footer"><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文博主：</strong> frezcirno</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/" title="Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism 论文阅读">https://frezcirno.github.io/2025/04/05/megatron-lm-training-multi-billion-parameter/</a></li><li class="post-copyright-license"><strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/MLSys/" rel="tag"># MLSys</a> <a href="/tags/Megatron-LM/" rel="tag"># Megatron-LM</a> <a href="/tags/Model-Parallelism/" rel="tag"># Model Parallelism</a> <a href="/tags/Distributed-Training/" rel="tag"># Distributed Training</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2025/04/04/a-generic-communication-scheduler/" rel="prev" title="A Generic Communication Scheduler for Distributed DNN Training Acceleration 论文阅读"><i class="fa fa-angle-left"></i> A Generic Communication Scheduler for Distributed DNN Training Acceleration 论文阅读</a></div><div class="post-nav-item"><a href="/2025/04/06/a-unified-architecture-for-accelerating/" rel="next" title="A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters 论文阅读">A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters 论文阅读<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">© 2020 – <span itemprop="copyrightYear">2025</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">frezcirno</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i></span> <span title="站点总字数">152k</span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">9:14</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> &amp; <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==">NexT.Gemini</span> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"frezcirno/frezcirno.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.22.0/third-party/comments/utterances.min.js" defer></script><script>if(window.matchMedia("(min-width: 760px)").matches){var js=document.createElement("script");js.type="text/javascript",js.defer=!0,js.src="https://cdn.jsdelivr.net/gh/frezcirno/static/live2d-widget/autoload.js",document.head.append(js)}</script></body></html>